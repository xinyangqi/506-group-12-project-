---
title: "STATS 506 Group Project"
author: "Group 12 - Ting-Wei Lin, Xinyang Qi, Jingwen Xiao"
date: "12/11/2019"
output: html_document
---

# Splines

### Introduction

The main question we are interested in is "Does people with more physial activity
get longer sleep?". A new study concludes that people sleep significantly better
and feel more alert during the day if they get at least 150 minutes of exercise a
week. Physical activity seems to have a positive effect on people's sleeping
condition, so we want to see it from real data if our data shows the same results.

Moreover, there are many factors that can affect our sleeping condition. Like the
amount of caffeine or sugar taken in a day, age and race etc. will also potentially
affect on sleeping condition. People usually think taking more caffine will have
less sleep and people with larger age will have less sleep.

Our analysis will show whether the factors we considered are significant to
sleeping time and if the relationships between each predictors and response
variable are the same as our hypotesis.


### Datasets and variables:

NHANES 2005-2006

Questionaire - 

Sleep Disorders - SLD010H (How much sleep do you get (hr.)?), 
Physical Activity - PAD080 ( How long per day(min.)), 
PAQ520 (Compare activity w/ other same age)
Physical Activity (individual ) - PADTIMES (# of times did activity in past 30 days), 
PADDURAT (Avg duration of activity(min.))
 
Dietary - 

DR1IKCAL(Energy (kcal)), DR1ISUGR (Total sugars (gm)), DR1ICAFF (Caffeine (mg))
DR2IKCAL(Energy (kcal)), DR2ISUGR (Total sugars (gm)), DR2ICAFF (Caffeine (mg))

Demographic - 

seqn, RIDGENDR (gender), RIDAGEYR (age), RIDRETH1(race/ethnicity), INDFMINC(annual family income), RIDEXMON

Utenlized variables:
  
  |  Variable Name  | Description | Type | Note |
  |:---------------:|:------------------:|:-----------------:|:-----------------:|
  |  seqn |     sequential number  |    integer     |    -     |
  |  gender |     gender of respondent       |      factor     |  1=male, 0=female |
  |  age  |     age of respondent       |     continuous     |  -  |
  |  inc  |     family income       |      continuous     |   - |
  | winter  |     whether surveyed in winter       |      factor     |    1=yes, 0=no      |
  | alcohol  |     alcohol drinks per day       |      integer     |    -    |
  | energy(_1)  |     daily energy intake       |      continuous     |    -      |
  | sugar(_1)  |     sugar intake       |      continuous     |    -      |
  | caffe(_1)  |     caffeine intake       |      continuous     |    -      |
  | sleep  |     hours of sleep       |      continuous     |  will be converted to  double   |
  | Mex  |     is Mexican American       |      factor   |  converted from **race**, 1=yes, 0=no      |
  | Hisp  |     is other Hispanic  |      factor     |    converted from **race**, 1=yes, 0=no      |
  | NHwhite  |is non-Hispanic white  |  factor |  converted from **race**, 1=yes, 0=no      |
  | NHblack  |  is non-Hispanic black  |  factor     |   converted from **race**, 1=yes, 0=no      |
  | pa_high  | more physically active than people of same age| factor  |converted from **pa_comp**, 1=yes, 0=no |
  |pa_low|less physically active than people of same age|factor|converted from **pa_comp**, 1=yes, 0=no   |
  | pad |how much physical activity last month|continuous|converted from **pa_time** and **pa_dur**, in minutes |
  
  
  Original data missing situations:
  
  |  Variable Name  | Missing amount | Note |
  |:---------------:|:------------------:|:------------------:|
  |seqn        |0|  -|
  |gender     |0|-|
  |age       |0|-|
  |race     | 0|-|
  |inc   |166|-|
  |winter | 649|-|
  |alcohol | 13606|-|
  |pa_time  |5457|physical activity times|
  |pa_dur  |5453|physical activity duration|
  |pa_comp |3197|physical activity compared to people of same age|
  |energy_1 | 1691|-|
  |sugar_1 |1691|-|
  |caffe_1  |1691|-|
  |sleep |6608|-|

### Methods 

Jingwen Xiao: R (dplyr for data processing and ggplot2 on visualization)

Tingwei Lin: R (data.table for data processing and base on visualization)

Xinyang Qi: Python

### Introduction of Spline and Spline Regression

Spline refers to a wide class of functions that are used in data interpolation and/or smoothing.

In this report, we will use only univariate polynomial case, so we limit our introduction to univariate polynomial case. 

In this case, a spline is a piecewise polynomial function. This function, call it S, takes values from an interval $[a,b]$ and maps them to $R$. That is,
$$S : [a,b] \rightarrow R$$

We want S to be piecewise defined. To accomplish this, let the interval [a,b] be covered by k ordered, disjoint subintervals, that is :
$$[t_i,t_{i+1}] , i = 0,...,k-1$$
$$[a,b]=[t_0,t_1]\cup[t_1,t_2]\cup...\cup[t_{k-2},t_{t-1}]\cup[t_{k-1},t_k]$$
$$a=t_0\leq t_1\leq...\leq t_{k-1}\leq t_k =b$$
On each of these k "pieces" of $[a,b]$, we want to define a polynomial, call it $P_i$.
$$P_i:[t_i,t_{t+1}] \rightarrow R$$
On the ith subinterval of $[a,b]$, S is defined by $P_i$,
$$S(t)=P_0(t),t_0\leq t \leq t_1$$
$$S(t)=P_1(t),t_1\leq t \leq t_2$$
$$...$$
$$S(t)=P_{k-1}(t),t_{k-1}\leq t \leq t_k$$
The given k+1 points ti are called knots. The vector $t=(t_0,...,t_k)$ is called a knot vector for the spline.

If the polynomial pieces Pi each have degree at most n, then the spline is said to be of $degree\leq n$ (or of order n+1).

The spline regression uses a combination of linear/polynomial functions to fit the data. It is a non-linear approach.

The Linear Regression assumes a linear relationship between the dependent and independent variables, which was rarely the case in reality. In this case, the spline regression can usually improve the fit.

# {.tabset .tabset-fade .tabset-pills}

## R (data.table)
```{r, message=FALSE}
# libraries: -------------------------------------------------------------------
library(Hmisc)
library(data.table)
library(splines)
```

```{r, result = "hide", message=FALSE}
# data: ------------------------------------------------------------------------
path = "/Users/Sabrina/Documents/2019UMICH/STATS506/group project/data/"

sleep = as.data.table(sasxport.get(paste0(path, "SLQ_D.XPT")))
alc =  as.data.table(sasxport.get(paste0(path, "ALQ_D.xpt")))
physical = as.data.table(sasxport.get(paste0(path, "PAQ_D.XPT")))
physical_indv = as.data.table(sasxport.get(paste0(path, "PAQIAF_D.XPT")))
demo = as.data.table(sasxport.get(paste0(path, "DEMO_D.XPT")))
dietary1 = as.data.table(sasxport.get(paste0(path, "DR1TOT_D.XPT")))
dietary2 = as.data.table(sasxport.get(paste0(path, "DR2TOT_D.XPT")))
```

Data cleaning, delete the ones that have no correct response
```{r}
# 80: --------------------------------------------------------------------------

# keep the variables we need, and filter the unreasonale data
sleep = sleep[sld010h < 77, .(seqn, sld010h)]
alc = alc[alq130 < 100,.(seqn, alq130)]
physical = physical[paq520 < 7, .(seqn, paq520)]
physical_indv = physical_indv[, .(seqn, padtimes, paddurat)]
demo = demo[indfminc < 12, .(seqn, riagendr, ridageyr, ridreth1, indfminc, ridexmon)]
dietary1 = dietary1[, .(seqn, dr1tkcal, dr1tsugr, dr1tcaff)]
# rename colnames
names(dietary1) = c("seqn", "drtkcal", "drtsugr", "drtcaff")
```

### Part 1. Fit OLS model for all variables in the dataset.

```{r}
# merge day 1 data
data1 = merge(sleep, physical, all = TRUE)
data1 = merge(data1, alc, all = TRUE)
data1 = merge(data1, physical_indv, all = TRUE)
data1 = merge(data1, demo, all = TRUE)
data1 = merge(data1, dietary1, all = TRUE)

# rename colnames
names(data1) = c("seqn", "sleep", "pa_comp", "alcohol", "padtimes", 
                 "paddurat", "gender", "age", "race", "inc", "winter", 
                 "energy", "sugar", "caffeine")

# omit the rows that have missing values
data1_naomit = data1[complete.cases(data1[])]
```

Timing "paddurat" and "padtimes" then divide it by 60 to get "pad".
"pad" = total activity times in past 30 days in hours.
```{r}
# compute total activity times (hr.) in past 30 days
data1_pad = data1_naomit[, .(pad = paddurat*padtimes/60)]
# cbind two dataset
data1_use = cbind(data1_naomit, data1_pad)
```

We take mean for each variables within the same seqn (id) group. 
To avoid repeated seqn appears in the dataset.
Then decode the factor variables into seperate categories.
After cleaning the data, we'll get 1769 observation for this dataset.
```{r}
# take mean for repeated seqn
data1_avg_value = data1_use[, lapply(.SD, mean), by = .(seqn), 
                    .SDcols = c("sleep", "alcohol", "pa_comp", 
                                "padtimes", "paddurat", "age", "race", 
                                "inc", "winter", "gender", "energy",
                                "sugar", "caffeine", "pad")]
# decode the factors
data_new1 = data1_avg_value[, `:=` (Mex = 1L * {race == 1},
              Hisp = 1L * {race == 2}, NHwhite = 1L * {race == 3}, 
              NHblack = 1L * {race == 4}, pa_high = 1L * {pa_comp == 1}, 
              pa_low = 1L * {pa_comp == 2}, winter = 1L * {winter == 1})]
```

Fit OLS model for all variables in the dataset.
```{r}
# fit linear model for all variables
model_lm1 = lm(sleep ~ alcohol + energy + sugar + caffeine + 
                 as.factor(gender) + age + as.factor(inc) + as.factor(winter) + 
                 as.factor(Mex) + as.factor(Hisp) + as.factor(NHwhite)+
                 as.factor(NHblack) + as.factor(pa_high) + as.factor(pa_low) + 
                 pad, data = data_new1)

summary(model_lm1)
```

We found out that the Adjusted $R^2$ is really low and it contains a lot of
variables with large p-values. Hence, we decided to do variables selection
to reduce variables in our model.

```{r}
# variable selection ( drop the variables the has large p-value)
model_lm2 = lm(sleep ~ as.factor(Mex) + as.factor(NHwhite) + as.factor(NHblack) + 
                as.factor(pa_low) + age + alcohol + pad + sugar + caffeine, 
               data = data_new1)

summary(model_lm2)
```

The Adjusted $R^2$ is still really low for our fitted model after selecting variables.
So We decided to use spline regression to improve our model fitting result.

### Part 2. Fit spline regression to improve our model fitting result.

First, we look at the relarionship between only "pad" and "sleep"
```{r}
# fit model for "pad" variable
model_pad1 = lm(sleep ~ pad,  data = data_new1)
summary(model_pad1)
coef(model_pad1) # extract coefficient
```

Plot for "sleep" and "pad" to see the relationship between Activity times and sleeping hours with 1769 obs.
```{r}
# plot relationship between Activity times and sleeping hours
plot(data_new1$pad, data_new1$sleep, col="darkblue"
     ,xlab="Activity times (hr.)", ylab="Sleep (hr.)",
     main = "Relationship between Activity times and sleeping hours (1769 obs)")
# add regression line to the plot
abline(coef(model_pad1)[1], coef(model_pad1)[2], col = "red")
# add legend
legend(200, 12, legend = "Prediction Line",
      col="red", lty = 1, cex=0.8)
```

The data only has 1769 observations, so we decided to re-merge the data and select
only "sleep" and "physical_indv" data.
```{r}
# create another dataset to fit only sleep and pad
data2 = merge(sleep, physical_indv, all = TRUE)
# rename colnames
names(data2) = c("seqn", "sleep", "padtimes", "paddurat")

# omit the rows that have missing values
data2_naomit = data2[complete.cases(data2[])]
# compute total activity times (hr.) in past 30 days
data2_pad = data2_naomit[, .(pad = paddurat*padtimes/60)]
# cbind two dataset
data2_use = cbind(data2_naomit, data2_pad)

# take mean for repeated seqn
data2_avg_value = data2_use[, lapply(.SD, mean), by = .(seqn), 
                           .SDcols = c("sleep", "padtimes", "paddurat", "pad")]
```

Now we have a dataset with 3946 observations.

We look at the relarionship between only "pad" and "sleep" for larger dataset.
```{r}
# fit model for "pad" variable
model_pad2 = lm(sleep ~ pad,  data = data2_avg_value)
summary(model_pad2)
coef(model_pad2) # extract colnames
```

Plot for "sleep" and "pad" to see the relationship between Activity times and sleeping hours with 3946 obs.
```{r}
# plot relationship between Activity times and sleeping hours
plot(data2_avg_value$pad, data2_avg_value$sleep, col="darkblue"
     ,xlab="Activity times (hr.)", ylab="Sleep (hr.)",
     main = "Relationship between Activity times and sleeping hours (3946 obs)")
# add regression line to the plot
abline(coef(model_pad2)[1], coef(model_pad2)[2], col = "red")
# add legend
legend(200, 12, legend = "Prediction Line",
      col="red", lty = 1, cex=0.8)
```

Reported sleep should be an approximate value. Add a jitter so that 
more respondents get the right approximated value, and we can make "sleep" a
"continuous" variable.
```{r}
# create jitter
random = rnorm(nrow(data2_avg_value), 0, 0.1)
# add jitter to "sleep" variable
data_new2 = data2_avg_value[, .(sleep = sleep + random, pad)]
```

To compare the effect of spline on "pad" variable, we first fit linear regression 
for "sleep" and "pad", then we fit spline regression for "sleep" and "pad".

Fit linear model for "pad" and "sleep" after adding jitter to "sleep".

```{r}
# do spline for "pad" variable
model_lm3 = lm(sleep ~ pad,  data = data_new2)
summary(model_lm3)
coef(model_lm3) # extract coefficient
```

Fit Spline model for "pad" and "sleep" after adding jitter to "sleep".

```{r}
# do spline for "pad" variable
spline_model = lm(sleep ~ bs(pad, df = 3),  data = data_new2)
summary(spline_model)
```

Plot to compare regression line before and after splines.
```{r}
# plot splines results compare with the one without spline
plot(data_new2$pad, data_new2$sleep, 
     col="grey", xlab="Activity times (hr.)", ylab="Sleep (hr.) with jitter", 
     main = "Splines Regression Result")
fit1 = smooth.spline(data_new2$pad, data_new2$sleep, df=3) 
abline(coef(model_lm3)[1], coef(model_lm3)[2], col = "yellow")
lines(fit1, col="red",lwd=2)
legend(200, 10, legend=c("Spline", "Without Spline"),
       col=c("red", "yellow"), lty = 1, cex=0.8)
```


### Summary

  To sum up, people getting more physical activity doesn't lead to more sleeping
hours. However, intaking less alcohol or caffeine do increase sleeping hours.
Although some research said that getting more physical activity will lead to a
better sleeping, in our analysis, we do not find physical activity significantly
related to sleeping hours. In fact there is almost no obvious relation between
those two variables.

  After fitting activity hours (pad) to a spline regression, it did fits the model
a bit better. But the relationship between physical activity and sleeping hours is
still not obvious. So we cannot say people with more physical activity
get longer sleep in this case.

## Python
```{r setup, include = FALSE}
library(reticulate)
use_python("/usr/local/bin/python")
```

Firstly, import package and read data.

```{python,eval=FALSE}
import pandas as pd
import numpy as np
import statsmodels.api as sm
import statsmodels.formula.api as smf
from patsy import dmatrices
from patsy import dmatrix
from statsmodels.stats.outliers_influence import variance_inflation_factor
import matplotlib.pyplot as plt

data1=pd.read_sas('ALQ_D.xpt')
data2=pd.read_sas('PAQ_D.xpt')
data3=pd.read_sas('PAQIAF_D.xpt')
data4=pd.read_sas('SLQ_D.xpt')
data5=pd.read_sas('DR1TOT_D.xpt')
data6=pd.read_sas('DEMO_D.xpt')
```

Then, extract and clean data.

```{python,eval=FALSE}
data1=data1[['SEQN','ALQ130']]
data2=data2[['SEQN','PAQ520']]
data4=data4[['SEQN','SLD010H']]
data3=data3[['SEQN','PADTIMES','PADDURAT']]
data5=data5[['SEQN','DR1TKCAL','DR1TSUGR','DR1TCAFF']]
data6=data6[['SEQN','RIAGENDR','RIDAGEYR','RIDRETH1','INDFMINC','RIDEXMON']]

data=data[(data.PAQ520 != 9)&(data.PAQ520 != 7)]
data=data[(data.SLD010H != 77) & (data.SLD010H != 99)]
data=data[data.INDFMINC < 12]
data=data[data.ALQ130<800]
data=data.dropna()
data=data.groupby('SEQN').mean()

data.columns=['alcohol','act_level','act_times','act_durat','sleep','energy','sugars','caffeine','gender','age','race','inc','winter']

data['gender']=data['gender']-1
data['Mex']=1*(data['race']==1)
data['Hisp']=1*(data['race']==2)
data['NHwhite']=1*(data['race']==3)
data['NHblack']=1*(data['race']==4)
data['pa_high']=1*(data['act_level']==1)
data['pa_low']=1*(data['act_level']==2)
data['winter']=1*(data['winter']==1)
data['pad']=data['act_times']*data['act_durat']/60
data=data.drop(['act_level','act_times','act_durat','race'],axis=1)

data['gender']=data['gender'].apply(str)
data['Mex']=data['Mex'].apply(str)
data['Hisp']=data['Hisp'].apply(str)
data['NHwhite']=data['NHwhite'].apply(str)
data['NHblack']=data['NHblack'].apply(str)
data['pa_high']=data['pa_high'].apply(str)
data['pa_low']=data['pa_low'].apply(str)
data['winter']=data['winter'].apply(str)
```

### Part 1
Firstly, we create a model with all predictors in order to find the effect of activity time and other factors on sleep time.

```{python,eval=FALSE}
mod1 = smf.ols(formula='sleep ~ alcohol+energy+sugars+caffeine+gender+age+inc+winter+Mex+Hisp+NHwhite+NHblack+pa_high+pa_low+pad', data=data)
res1 = mod1.fit()
print(res1.summary())
```
![](/Users/Sabrina/picture1.png)


Then, in order to improve the model, we select variables based on their vif and Covariance matrix at first. Then, using backward elimination to select variables.

Create an OLS regression model based on a subset of variables. 

Based on the summary below, the value of adjusted R square increases and we get a better model. 

```{python,eval=FALSE}
mod2 = smf.ols(formula='sleep ~ C(Mex)+C(NHwhite)+C(NHblack)+C(pa_low)+age+alcohol+pad+sugars+caffeine',data=data).fit()
mod2.summary()
```

![](/Users/Sabrina/picture2.png)

From the summary above, we find that compared with other predictors, the effect of activity time is not very significant.

### Part 2

secondly, we will create model to analyse the relationship between activity time and sleep time. 


```{python,eval=FALSE}
mod3 = smf.ols(formula='sleep ~ pad',data = data).fit()
mod3.summary()
```

![](/Users/Sabrina/picture3.png)


```{python,eval=FALSE}
plt.scatter(data.pad,data.sleep)
plt.plot(data.pad,mod3.predict(),color = 'red')
plt.show()
```

![](/Users/Sabrina/picture4.png)

From the graph above, we find that although the fitted line has a curvature, it is not convincing.

Because alcohol data is not available for respondents age under 20, we try to create model with full dataset.

And because reported sleep should be an approximate value, we will give each sleep time a random disturbance to let 'sleep time' become a continuous variable. 

```{python,eval=FALSE}
data_pad = pd.merge(data3,data4,on='SEQN',how='inner')
data_pad = data_pad[data_pad.SLD010H != 77]
data_pad = data_pad[data_pad.SLD010H != 99]
data_pad = data_pad.dropna()
data_pad = data_pad.groupby('SEQN').mean()
data_pad['pad']=data_pad['PADTIMES']*data_pad['PADDURAT']/60
data_pad = data_pad.drop(['PADTIMES','PADDURAT'],axis=1)
data_pad.columns = ['sleep','pad']
data_pad = data_pad['sleep']
eps = np.random.normal(0,0.1,size = data_pad.shape[0])
data_pad['sleep']=data_pad['sleep']+eps
mod6 = smf.ols(formula='sleep ~ pad',data = data_pad).fit()
mod6.summary()
```

![](/Users/Sabrina/picture5.png)


```{python,eval=FALSE}
plt.scatter(data_pad.pad,data_pad.sleep)
plt.plot(data_pad.pad,mod6.predict(),color = 'red')
plt.show()
```

![](/Users/Sabrina/picture6.png)

From the summary, we can find that activity time still have very little effect on sleep time. 
Maybe the activity time does not have a linear relationship with sleep time. So we decide to use spline regression to try to improve its fit.

```{python,eval=FALSE}
transformed_x1 = dmatrix("bs(data_pad.pad, df=3, degree = 3, include_intercept=False)",
                        {"data_pad.pad": data_pad.pad}, return_type='dataframe')
mod7 = sm.GLM(data_pad.sleep, transformed_x1).fit()
print(mod7.summary())
```

![](/Users/Sabrina/picture7.png)

```{python,eval=FALSE}
plt.scatter(data_pad.pad,data_pad.sleep)
plt.plot(data_pad.pad,mod7.predict(),color = 'red')
plt.show()
```

![](/Users/Sabrina/picture8.png)

Based on the summary and graph above, although the spline regression improve the fit slightly, the relationship between sleep time and activity time is still not strong.

Base on all the analyse above, although all models have a weak trend that people who do activity for longer time tend to sleep less, we have to conclude that compared with the effect of alcohol and caffeine on sleep time, the effect of activity time is much little.

## R (dplyr)


First read data and import packages. 
```{r}
library(SASxport)
library(dplyr)
library(mgcv)
library(tidyr)
library(ggplot2)
library(kableExtra)
alc = read.xport(paste0(path, "ALQ_D.xpt"))
phy = read.xport(paste0(path, "PAQ_D.xpt"))
phy_id = read.xport(paste0(path, "PAQIAF_D.xpt"))
slp = read.xport(paste0(path, "SLQ_D.xpt"))
demo = read.xport(paste0(path, "DEMO_D.xpt"))
total_d1 = read.xport(paste0(path, "DR1TOT_D.xpt"))
```

Select variables that might be of interest.

```{r}
alc = alc %>% transmute(seqn = SEQN, alcohol = ALQ130)
phy = phy %>% transmute(seqn = SEQN, pa_comp = PAQ520)
phy_id = phy_id %>% transmute(seqn = SEQN, pa_time = PADTIMES, pa_dur = PADDURAT)
slp = slp %>% transmute(seqn = SEQN, sleep = SLD010H)
demo = demo %>% transmute(seqn = SEQN, gender = RIAGENDR, age = RIDAGEYR, 
                          race = RIDRETH1, inc = INDFMINC, winter = RIDEXMON)
total_d1 = total_d1 %>% transmute(seqn = SEQN, energy_1 = DR1TKCAL, 
                                  sugar_1 = DR1TSUGR, caffe_1 = DR1TCAFF)
```

Day 2 data is currently dropped to get more complete observations. Currently $n = 1769$.

Merge dataframes and recode factor variables. An uncoded version is available in the second following chunk.

```{r}
data = left_join(demo, alc, by="seqn") %>% left_join(phy_id, by="seqn") %>% 
       left_join(phy, by = "seqn") %>% left_join(total_d1, "seqn") %>% 
       left_join(slp, "seqn") 
```

Before moving on, we perform a quick check on the number of missing values in each variable to get a better view of the current dataset.

```{r}
colSums(apply(data, 2, is.na))
```

Results of this part is available in the data description. Now we recode some of the variables and get rid of observations with numeric codes representing "refuse" or "don't know". Another version with no factor recode is shown in the second chunk.

```{r}
data = data %>% filter(!is.na(sleep), pa_comp%in%c(1, 2, 3), 
         alcohol!=999, sleep<77, inc<12) %>% mutate(gender = ifelse(gender==1, 1, 0), 
         Mex = ifelse(race == 1, 1, 0), Hisp = ifelse(race == 2, 1, 0), 
         NHwhite = ifelse(race == 3, 1, 0), NHblack = ifelse(race == 4, 1, 0), 
         pa_high = ifelse(pa_comp == 1, 1, 0), pa_low = ifelse(pa_comp == 2, 1, 0),
         winter = ifelse(winter == 1, 1, 0), pad = pa_time*pa_dur/60) %>% 
       select(-c("race","pa_comp", "pa_time", "pa_dur"))
```
```{r}
data1 = left_join(demo, alc, by="seqn") %>% left_join(phy_id, by="seqn") %>% 
  left_join(phy, by = "seqn") %>% left_join(total_d1, "seqn") %>% 
  left_join(slp, "seqn") %>% filter(!is.na(sleep), pa_comp%in%c(1, 2, 3), 
            alcohol!=999, sleep<77, inc<12) %>% mutate(gender = ifelse(gender==1, 1, 0), 
            winter = ifelse(winter == 1, 1, 0), pad = pa_time*pa_dur/60) %>% 
  select(-c("pa_time", "pa_dur"))
```

Now remove incomplete observaions.

```{r}
dat = data[complete.cases(data),] %>% group_by(seqn) %>% 
      mutate(pad = mean(pad)) %>% distinct()
dat1 = data1[complete.cases(data1),] %>% group_by(seqn) %>% 
       mutate(pad = mean(pad)) %>% distinct()
```

For the analysis part, it is always a nice choice to first perform an OLS. The $R^2$ of this model is around 0.0576, with an adjusted $R^2$ of about 0.0495.

```{r}
result0=lm(sleep~as.factor(gender) + age + inc + as.factor(winter) +
             alcohol + energy_1 + sugar_1 + caffe_1 + as.factor(Mex) + as.factor(Hisp) +
             as.factor(NHwhite) + as.factor(NHblack) + as.factor(pa_high) +
             as.factor(pa_low) + pad, data=dat)
summary(result0)
```

Next fit a GAM on both processed data sets. The total deviation explained is 8.26%, obviously better than the OLS result. Adjusted $R^2$ dropped a little (~0.07) when factor variables are not recoded, so the recoded version will be kept in later versions.

```{r}
result=gam(sleep~as.factor(Mex)+as.factor(NHwhite)+as.factor(NHblack)+
           as.factor(pa_low)+s(age)+s(alcohol)+s(pad)+
           s(energy_1)+s(sugar_1)+s(caffe_1),data=dat)
summary(result)
```
```{r}
result1=gam(sleep~as.factor(race)+as.factor(pa_comp)+
            s(age)+s(alcohol)+s(pad)+s(energy_1)+s(sugar_1)+
            s(caffe_1),data=dat1)
summary(result1)
```

To have a look on the effect of variable **pad**, we use spline regression for this term only. The output plot shows a straight line and is strongly affected by two points with extreme **pad** values.

```{r}
res_pad = gam(sleep ~ s(pad), data = dat)
df = data.frame(x = dat$pad, y=dat$sleep, z=fitted(res_pad))
ggplot(df) + geom_point(aes(x = x, y = y), col="cornflowerblue") + 
  geom_line(aes(x = x, y = z),col = "gray") + 
  labs(x = "Monthly Physical Activity(hour)", y = "Sleep")
```

Now we discard the two large points. We somehow got a curvature in the plot, but the discrepancy is not very much convincing.

```{r}
dat2 = as.data.frame(dat[dat$pad<200, ])
res_pad1 = gam(sleep~s(pad), data = dat2)
df1 = data.frame(x = dat2$pad, y = dat2$sleep, z = fitted(res_pad1))
ggplot(df1) + geom_point(aes(x = x, y = y), col = "cornflowerblue") + 
  geom_line(aes(x = x, y = z), col = "gray") + 
  labs(x = "Monthly Physical Activity(hour)", y = "Sleep")
```

Since there could be a difference between the complete observations and incomplete observations, we perform the same actions on the full dataset, only dropping observations with missing values on **pad** and **sleep**. However, since we witnessed only a slight downward trend in this part of data, it seems that the response itself is somewhat random.

```{r}
data_pad = left_join(slp, phy, by="seqn") %>% 
  left_join(phy_id, by="seqn") %>% filter(!is.na(sleep), sleep<77) %>% 
  mutate(pad = pa_time*pa_dur/60) %>% select(-c("pa_time", "pa_dur"))
data_pad = data_pad%>%filter(rowSums(apply(data_pad,2,is.na))==0) %>% select(-"pa_comp")%>%
  group_by(seqn) %>% mutate(pad = mean(pad)) %>% distinct()
res_pad2 = gam(sleep~s(pad), data = data_pad)
df2 = data.frame(x = data_pad$pad, y = data_pad$sleep, z = fitted(res_pad2))
ggplot(df2) + geom_point(aes(x = x, y = y), col = "cornflowerblue") + 
  geom_line(aes(x = x, y =z ), col = "gray") + 
  labs(x = "Monthly Physical Activity(hour)", y = "Sleep")
```

Now that we know that data selection is not really the problem, we could turn back to the truncated data. We assume that reported sleeping hours should be an approximate value, so a jitter is added to mimic real-life scenarios, which also converts **sleep** to the type "continuous". Keep in mind that we hope that most of the respondents should get the right approximated value. In this case, $\sigma=0.2$ is chosen to guarantee that at least 99% of the values are approximated to the reported integer.

```{r}
eps=rnorm(nrow(dat2), 0, 0.04)
dat_eps = as.data.frame(dat[dat$pad<200, ])
dat_eps = dat_eps %>% mutate(sleep = as.numeric(sleep)+eps)
res_eps_pad = gam(sleep~s(pad), data = dat_eps)
df_eps = data.frame(x=dat_eps$pad,y=dat_eps$sleep, z=fitted(res_eps_pad))
ggplot(df_eps) + geom_point(aes(x=x,y=y),col="cornflowerblue") + 
  geom_line(aes(x=x,y=z),col="gray") + 
  labs(x = "Monthly Physical Activity(hour)", y = "Sleep")
```

For comparison, consider OLS and polynomials of power 2 and 3. Though no model is reporting a significant contribution from **pad**, it seems that the spline model is still doing better.

```{r}
ols_eps = lm(sleep~pad, dat_eps)
summary(ols_eps) 
poly_eps2 = lm(sleep~poly(pad, 2),dat_eps)
summary(poly_eps2) 
poly_eps3 = lm(sleep~poly(pad,3),dat_eps) 
summary(poly_eps3) 
```

To have a closer look on the effects, we perform 10-fold cross validation and RMSE calculation with these four models. Unfortunately, spline method is not performing well in the CV part.

```{r}
N = nrow(dat_eps)
ind = rep(1:10, N%/%10+1)[1:N]
r_ind=sample(ind, N, F)
mat_rmse=matrix(0,10,4)
for (i in 1:10){
  train = dat_eps[r_ind!=i, ]
  test = dat_eps[r_ind==i, ]
  test_x=test%>%select(-"sleep")
  test_y=test[,"sleep"]   
  ols_train = lm(sleep~pad, data = train)
  ols_test=predict(ols_train,test_x)
  p2_train = lm(sleep~poly(pad,2), data = train)
  p2_test=predict(p2_train,test_x)
  p3_train = lm(sleep~poly(pad,3), data = train)
  p3_test=predict(p3_train,test_x)
  gam_train = gam(sleep~s(pad), data = train)
  gam_test=predict(gam_train,test_x)
  mat_rmse[i,1]=sqrt(mean((test_y-ols_test)^2))
  mat_rmse[i,2]=sqrt(mean((test_y-p2_test)^2))
  mat_rmse[i,3]=sqrt(mean((test_y-p3_test)^2))
  mat_rmse[i,4]=sqrt(mean((test_y-gam_test)^2))
}
```
```{r}
names = c('OLS', 'Polynomial(2)', 'Polynomial(3)', 'Spline/GAM')
CV = colMeans(mat_rmse) 
cap_title1 = '**Table 1.** *Cross-validation Results of Different Models.*'
cols = c('OLS','Polynomial(2)','Polynomial(3)','Spline/GAM')
kable(t(CV), digits = 4, caption = cap_title1, col.names = cols, align = 'c')%>%
      kable_styling("striped", position = "center")
```

However, spline method is slightly better in RMSE than others when using the whole dataset.

```{r}
rmse = function(method){
 round(sqrt(mean(method$residual^2)),5)
}
rmse_ols = rmse(ols_eps)
rmse_poly2 = rmse(poly_eps2)
rmse_poly3 = rmse(poly_eps3)
rmse_gam = rmse(res_eps_pad)
RMSE =c(rmse_ols, rmse_poly2, rmse_poly3, rmse_gam)
cap_title2 = '**Table 2.** *Full-data RMSE Results of Different Models.*'
kable(t(RMSE), digits = 4, caption = cap_title2, col.names = cols, align = 'c')%>%
  kable_styling("striped", position = "center")
```

To this point, we have to re-think whether physical activity really have a discriminative effect on the sleep time. In fact, the sleep time that people need is rather random, and the contribution from other factors are somewhat minor.



